{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f195df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model-----------------Status: Done\n",
      "Index(['Width,Height,Roi.X1,Roi.Y1,Roi.X2,Roi.Y2,ClassId,Path'], dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/my_new_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/my_new_env/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_new_env/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Path'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 212\u001b[0m\n\u001b[1;32m    210\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet50_epochs30_backdoored.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m mydevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 212\u001b[0m \u001b[43mpredict_on_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_images_to_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmydevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 166\u001b[0m, in \u001b[0;36mpredict_on_directory\u001b[0;34m(directory_path, model_path, num_images_to_test, device)\u001b[0m\n\u001b[1;32m    162\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(model_path, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    164\u001b[0m class_names \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtsrb-german-traffic-sign/labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 166\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[43mget_ground_truth_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgtsrb-german-traffic-sign/Test.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mprint\u001b[39m(ground_truth[:\u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m    168\u001b[0m filenames \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(directory_path)\n",
      "Cell \u001b[0;32mIn[18], line 157\u001b[0m, in \u001b[0;36mget_ground_truth_from_csv\u001b[0;34m(csv_path)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns)  \u001b[38;5;66;03m# Print the columns to check\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Use os.path.basename() to extract just the image filename\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m filenames \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    158\u001b[0m truth_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(filenames, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassId\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m truth_dict\n",
      "File \u001b[0;32m~/anaconda3/envs/my_new_env/lib/python3.8/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/my_new_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Path'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet50,resnet152\n",
    "\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super().__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False,)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels,out_channels * self.expansion,kernel_size=1,stride=1,padding=0,bias=False,)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels,out_channels * 4,kernel_size=1,stride=stride,bias=False)\n",
    "                                                ,nn.BatchNorm2d(out_channels * 4))\n",
    "\n",
    "        layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = out_channels * 4\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "def ResNet50(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet101(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet152(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def load_model(model_path, num_classes=43, device=\"cpu\"):\n",
    "    model = resnet50(weights=None, num_classes=43).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    print(\"Loading Model-----------------Status: Done\")\n",
    "    return model\n",
    "\n",
    "def process_image(image_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((225, 225)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    # Apply transformations\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    return image_tensor, image\n",
    "\n",
    "def predict(image_path, model, device=\"cpu\"):\n",
    "    # No need to reload the model every time you predict. Use the passed model.\n",
    "    # model = load_model(model_path, device=device)\n",
    "    \n",
    "    image_tensor, image = process_image(image_path)  # Assume process_image returns (tensor, image)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted_class_index = torch.max(outputs, 1)\n",
    "\n",
    "    return predicted_class_index.item(), image\n",
    "\n",
    "def get_ground_truth_from_csv(csv_path):\n",
    "    \"\"\"Load the CSV file and return a dictionary with filenames as keys and labels as values.\"\"\"\n",
    "    data = pd.read_csv(csv_path, delimiter='\\t')  # Use the tab delimiter\n",
    "    print(data.columns)  # Print the columns to check\n",
    "    # Use os.path.basename() to extract just the image filename\n",
    "    filenames = data['Path'].apply(os.path.basename).tolist()\n",
    "    truth_dict = dict(zip(filenames, data['ClassId']))\n",
    "    return truth_dict\n",
    "\n",
    "def predict_on_directory(directory_path, model_path, num_images_to_test=None, device=\"cpu\"):\n",
    "    model = load_model(model_path, device=device)\n",
    "    \n",
    "    class_names = pd.read_csv('gtsrb-german-traffic-sign/labels.csv')['Name'].tolist()\n",
    "    \n",
    "    ground_truth = get_ground_truth_from_csv('gtsrb-german-traffic-sign/Test.csv')\n",
    "    print(ground_truth[:10])\n",
    "    filenames = os.listdir(directory_path)\n",
    "    random.shuffle(filenames)\n",
    "    \n",
    "    if num_images_to_test:\n",
    "        filenames = filenames[:num_images_to_test]\n",
    "\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    print(\"Starting Prediction....\")\n",
    "    for filename in filenames:\n",
    "        image_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        if image_path.lower().endswith('.ppm') or image_path.lower().endswith('.png'):\n",
    "            predicted_class_index, image = predict(image_path, model, device)\n",
    "            predicted_class_name = class_names[predicted_class_index]\n",
    "            \n",
    "            # Compare with ground truth\n",
    "            true_class_index = ground_truth.get(filename, None)\n",
    "            if true_class_index is not None:\n",
    "                total_count += 1\n",
    "                if predicted_class_index == true_class_index:\n",
    "                    correct_count += 1\n",
    "            \n",
    "#             print(f\"\\nImage: {filename}\")\n",
    "#             print(f\"Predicted Class ID: {predicted_class_index}\")\n",
    "#             print(f\"Predicted Class Name: {predicted_class_name}\")\n",
    "#             if true_class_index is not None:\n",
    "#                 print(f\"True Class ID: {true_class_index}\")\n",
    "#                 print(f\"True Class Name: {class_names[true_class_index]}\")\n",
    "\n",
    "#             plt.figure(figsize=(6, 6))\n",
    "#             plt.imshow(image)\n",
    "#             plt.title(f\"Predicted: {predicted_class_name}\")\n",
    "#             plt.axis('off')\n",
    "#             plt.show()\n",
    "\n",
    "    print(f\"\\nTotal Images Tested: {total_count}\")\n",
    "    print(f\"Correct Predictions: {correct_count}\")\n",
    "    print(f\"Average Accuracy: {correct_count / total_count * 100:.2f}%\")\n",
    "\n",
    "# Assuming the ground truth CSV is named 'GT-final_test.csv' and is located inside the 'test' directory\n",
    "test_directory = 'gtsrb-german-traffic-sign/Test'\n",
    "model_path = \"resnet50_epochs30_backdoored.pt\"\n",
    "mydevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "predict_on_directory(test_directory, model_path, num_images_to_test=20, device=mydevice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de5bc45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
